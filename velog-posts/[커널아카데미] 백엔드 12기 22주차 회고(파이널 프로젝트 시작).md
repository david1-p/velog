<blockquote>
<p>파이널 프로젝트를 시작했다.
카카오 알림톡 템플릿 자동 생성하는 프로젝트를 선택하였고, 나는 그중에서 AI 관련을 담당하게 되었다. RFP를 분석하고 내 생각들을 간단하게 정리해보았다. </p>
</blockquote>
<h4 id="문제의-본질과-프로젝트의-목표">문제의 본질과 프로젝트의 목표</h4>
<p>가장 먼저 집중했던 것은 RFP에 담긴 '문제의 본질'을 파악하는 것이었다. 이 프로젝트는 단순히 'AI 글쓰기'가 아니라, 소상공인이라는 명확한 고객이 겪는 '진짜 문제'를 푸는 것이 핵심이었다. 복잡한 정책 때문에 매번 템플릿 등록에 실패하는 그 답답함을 기술로 해결해줄 수 있다는 생각에, 프로젝트의 목표를 명확히 할 수 있었다. 사용자가 어떤 말을 툭 던지든, AI가 찰떡같이 알아듣고 정책에 맞는 템플릿을 '짠'하고 만들어주는 것. 그것이 우리가 만들어야 할 가치다.</p>
<h4 id="시스템-아키텍처와-ai-파이프라인-설계">시스템 아키텍처와 AI 파이프라인 설계</h4>
<p>목표를 정하고 나니 '어떻게 구현할 것인가'에 대한 고민이 시작됐다. 가장 중요한 원칙은 '생성'과 '검증'의 역할을 반드시 분리한다는 것이었다. LLM이 아무리 똑똑해도 가끔 엉뚱한 소리를 할 수 있는데, 정책이 중요한 이 서비스에서 그런 실수는 치명적이다.</p>
<p>그래서 다음과 같은 파이프라인을 구상했다.</p>
<blockquote>
<p><strong>사용자 입력 (자연어)</strong>을 받으면, <strong>AI 서버(Python/FastAPI)</strong>가 문장의 의도(Intent)와 변수(Variable)를 분석하고 템플릿 초안(JSON)을 생성한다.<br />
이 초안을 <strong>백엔드 서버(Java/Spring)</strong>가 넘겨받아 규칙 기반으로 정책을 깐깐하게 검증한다. <br />
검증을 통과하면 사용자에게 보여주고, 실패하면 구체적인 피드백을 알려주는 구조다. 이 방식이 가장 안정적이라는 확신이 들었다.</p>
</blockquote>
<h4 id="ai-모델-선정-전략-작게-시작해서-크게-키우기">AI 모델 선정 전략: 작게 시작해서 크게 키우기</h4>
<p>파이프라인이 정해지자, 핵심인 AI 모델을 어떻게 가져갈지 구체적인 전략을 세웠다. RFP의 'LLM 파인튜닝' 요구사항에 맞춰, <strong>'Gemma로 시작해서, 점진적으로 성능을 높여가자'</strong>는 결론을 내렸다.</p>
<blockquote>
<p>1차 (프로토타입): Gemma-2B-it-ko
가볍고 빨라서 초기 실험에 딱이다. 우리가 만든 데이터로 원하는 결과(JSON)가 잘 나오는지 빠르게 테스트하는 용도다.
2차 (성능 고도화): Llama-3-Ko-8B 또는 EEVE-Korean-10.8B
Gemma로 기본기를 다진 후, 서비스 완성도를 높일 때 투입할 모델이다. 더 똑똑한 만큼, 애매모호한 요청도 잘 알아들을 것으로 기대한다.</p>
</blockquote>
<h4 id="가장-큰-도전-과제-고품질-데이터셋-구축">가장 큰 도전 과제: 고품질 데이터셋 구축</h4>
<p>며칠간의 고민 끝에 도달한 가장 근본적이고 어려운 문제는 바로 <strong>'데이터'</strong>였다. 아무리 좋은 모델과 아키텍처가 있어도, AI에게 먹일 '밥', 즉 학습 데이터가 없으면 아무 소용이 없다.</p>
<p>결국 이 프로젝트의 성패는 <strong>'얼마나 현실적이고 정교한 Instruction 데이터셋을 만드느냐'</strong>에 달렸다. 카카오 가이드라인을 통째로 외운 것처럼 동작하게 만들려면, 아래와 같은 수많은 예시 데이터를 만들어야 한다. 다행히도 기업에서 심사 통과, 실패 데이터를 주셨다. 요 데이터를 바탕으로 학습을 시키면 될 것 같다. 물론 실패 데이터 또한 학습데이터로 넣어봐야겠다. </p>